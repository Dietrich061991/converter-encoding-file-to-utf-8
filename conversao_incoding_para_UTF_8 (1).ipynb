{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conversao_incoding_para_UTF-8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLY8eYaqsUGf"
      },
      "source": [
        "import codecs\n",
        "import sys\n",
        "import chardet     #biblioteca que lida com o tipo de encoding\n",
        "import re\n",
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_6FpAWIsxNw"
      },
      "source": [
        "### encontrar o tipo de encodiing olhando para 20 linhas no arquivo\n",
        "def predict_encoding(file_path, n_lines=20):\n",
        "    '''Prever a codificação de um arquivo usando chardet'''    \n",
        "    # Abra o arquivo como dados binários\n",
        "    with open(file_path, 'rb') as f:\n",
        "        # unir linhas binárias para um número especificado de linhas\n",
        "        rawdata = b''.join([f.readline() for _ in range(n_lines)])\n",
        "    return chardet.detect(rawdata)['encoding']\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wObJf9M5m-Y"
      },
      "source": [
        "## converte para utf \n",
        "def converte_utf(nome_entrada, nome_saida):\n",
        "  BLOCKSIZE = 1048576 # ou algum outro tamanho desejado em bytes\n",
        "  with codecs.open(nome_entrada, \"r\", predict_encoding(nome_entrada)) as sourceFile:\n",
        "    with codecs.open(nome_saida, \"w\", \"utf-8\") as targetFile:\n",
        "          while True:\n",
        "              contents = sourceFile.read(BLOCKSIZE)\n",
        "              if not contents:\n",
        "                  break\n",
        "              targetFile.write(contents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyLtGOOV1XZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c607a467-c69e-479b-93c1-cab0cd412e6c"
      },
      "source": [
        "#ver todos os arquivos\n",
        "onlyfiles = [f for f in listdir('/content/sample_data') if isfile(join('/content/sample_data', f))]\n",
        "onlyfiles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PARQUE_VOZ_AVANCADA_ENOVA_20201110.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5QX5AIQ6Sv3"
      },
      "source": [
        "#verificar o tipo de encoding de um arquivo especifico \n",
        "predict_encoding('/content/sample_data/PARQUE_VOZ_AVANCADA_ENOVA_20201110.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUIQ83mK6hym"
      },
      "source": [
        "## ver encoding de todos eles\n",
        "tipo_encoding=[]\n",
        "for files in onlyfiles:\n",
        "  tipo_encoding.append(predict_encoding('/content/sample_data/' +files) )\n",
        "tipo_encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fng5R9hhnHj5"
      },
      "source": [
        "## pegar aqueles que nao sao utf-8 e ascii(ASCII é um subconjunto de UTF-8. Qualquer arquivo codificado em ASCII também é UTF-8 válido.)\n",
        "indexes_nao_utf = [i for i,x in enumerate(tipo_encoding) if x not in ['utf-8','ascii']]\n",
        "indexes_nao_utf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6w5ZQm157Xv"
      },
      "source": [
        "## verificar se todos o novos arquivos tem formato utf-8\n",
        "for files in  [onlyfiles[i] for i in indexes_nao_utf]: \n",
        "  print(files, \":\",predict_encoding('/content/sample_data/' +files),'\\n' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD3hevDX4Dlw"
      },
      "source": [
        "## aplicar  apenas nos caras que nao tem formato utf \n",
        "for files in  [onlyfiles[i] for i in indexes_nao_utf] :\n",
        "  converte_utf('/content/sample_data/' +files,'/content/sample_data/arquivo_convertido/' +files )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71WKyO5q631n"
      },
      "source": [
        "## verificar se todos o novos arquivos tem formato utf-8\n",
        "onlyfiles_novo = [f for f in listdir('/content/sample_data/arquivo_convertido') if isfile(join('/content/sample_data/arquivo_convertido', f))]  \n",
        "for files in onlyfiles_novo:\n",
        "  print(files, \":\",predict_encoding('/content/sample_data/arquivo_convertido/' +files),'\\n' )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}